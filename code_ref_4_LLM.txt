
# mlb_game_simulator.py
import statsapi  # You'll need to install this: pip install MLB-StatsAPI
import random
import pandas as pd
from datetime import datetime, date, timezone  # Added timezone
import time  # For a slight delay to make simulation feel more "live"

# Constants from the original script
BALLPARK_COORDS = {
    'ARI': {'lat': 33.4456, 'lon': -112.0667, 'name': 'Chase Field'},
    'ATL': {'lat': 33.8908, 'lon': -84.4678, 'name': 'Truist Park'},
    'BAL': {'lat': 39.2838, 'lon': -76.6217, 'name': 'Oriole Park at Camden Yards'},
    'BOS': {'lat': 42.3467, 'lon': -71.0972, 'name': 'Fenway Park'},
    'CHC': {'lat': 41.9484, 'lon': -87.6553, 'name': 'Wrigley Field'},
    'CWS': {'lat': 41.8300, 'lon': -87.6338, 'name': 'Guaranteed Rate Field'},
    'CIN': {'lat': 39.0974, 'lon': -84.5070, 'name': 'Great American Ball Park'},
    'CLE': {'lat': 41.4960, 'lon': -81.6852, 'name': 'Progressive Field'},
    'COL': {'lat': 39.7562, 'lon': -104.9942, 'name': 'Coors Field'},
    'DET': {'lat': 42.3390, 'lon': -83.0485, 'name': 'Comerica Park'},
    'HOU': {'lat': 29.7573, 'lon': -95.3555, 'name': 'Minute Maid Park'},
    'KC': {'lat': 39.0517, 'lon': -94.4803, 'name': 'Kauffman Stadium'},
    'LAA': {'lat': 33.8003, 'lon': -117.8827, 'name': 'Angel Stadium'},
    'LAD': {'lat': 34.0739, 'lon': -118.2400, 'name': 'Dodger Stadium'},
    'MIA': {'lat': 25.7781, 'lon': -80.2196, 'name': 'loanDepot park'},
    'MIL': {'lat': 43.0280, 'lon': -87.9712, 'name': 'American Family Field'},
    'MIN': {'lat': 44.9817, 'lon': -93.2777, 'name': 'Target Field'},
    'NYM': {'lat': 40.7571, 'lon': -73.8458, 'name': 'Citi Field'},
    'NYY': {'lat': 40.8296, 'lon': -73.9262, 'name': 'Yankee Stadium'},
    'OAK': {'lat': 37.7510, 'lon': -122.2009, 'name': 'Oakland Coliseum'},
    'PHI': {'lat': 39.9061, 'lon': -75.1665, 'name': 'Citizens Bank Park'},
    'PIT': {'lat': 40.4469, 'lon': -80.0057, 'name': 'PNC Park'},
    'SD': {'lat': 32.7076, 'lon': -117.1570, 'name': 'Petco Park'},
    'SEA': {'lat': 47.5914, 'lon': -122.3325, 'name': 'T-Mobile Park'},
    'SF': {'lat': 37.7786, 'lon': -122.3893, 'name': 'Oracle Park'},
    'STL': {'lat': 38.6226, 'lon': -90.1928, 'name': 'Busch Stadium'},
    'TB': {'lat': 27.7682, 'lon': -82.6534, 'name': 'Tropicana Field'},
    'TEX': {'lat': 32.7513, 'lon': -97.0828, 'name': 'Globe Life Field'},
    'TOR': {'lat': 43.6414, 'lon': -79.3894, 'name': 'Rogers Centre'},
    'WSH': {'lat': 38.8730, 'lon': -77.0074, 'name': 'Nationals Park'},
    'DEFAULT': {'lat': 39.8283, 'lon': -98.5795, 'name': 'Unknown'}
}
TEAM_ABBR_MAP = {
    'CWS': 'CWS', 'CHW': 'CWS', 'CHC': 'CHC', 'NYM': 'NYM', 'NYY': 'NYY',
    'LAA': 'LAA', 'ANA': 'LAA', 'SD': 'SD', 'SDP': 'SD', 'SF': 'SF', 'SFG': 'SF',
    'TB': 'TB', 'TBR': 'TB', 'KC': 'KC', 'KCR': 'KC', 'WSH': 'WSH', 'WSN': 'WSH',
}

# --- Player Stat Initialization ---
def init_player_stats(player_id, player_name, position):
    stats = {
        'id': player_id,
        'name': player_name,
        'pos': position,
        'PA': 0, 'AB': 0, 'R': 0, 'H': 0, '2B': 0, '3B': 0, 'HR': 0,
        'RBI': 0, 'BB': 0, 'SO': 0, 'SB': 0, 'CS': 0
    }
    if position == "P":  # Pitcher specific
        stats.update({
            'IP': 0.0, 'ER': 0, 'P_SO': 0, 'P_BB': 0, 'P_HR': 0, 'BF': 0,  # Batters Faced
            'Pitches': 0, 'Strikes': 0  # Simplified pitch counts
        })
    return stats

# --- Simplified At-Bat Simulation ---
GENERIC_PROBS = {
    'OUT_SO': 0.22,
    'OUT_OTHER': 0.41,
    'WALK': 0.10,
    'SINGLE': 0.17,
    'DOUBLE': 0.06,
    'TRIPLE': 0.005,
    'HOMERUN': 0.035
}
total_prob = sum(GENERIC_PROBS.values())
if abs(total_prob - 1.0) > 0.001:
    GENERIC_PROBS['OUT_OTHER'] += (1.0 - total_prob)

def simulate_at_bat(batter_stats, pitcher_stats):
    outcome = random.choices(list(GENERIC_PROBS.keys()), weights=list(GENERIC_PROBS.values()), k=1)[0]
    batter_stats['PA'] += 1
    pitcher_stats['BF'] += 1
    pitches_this_ab = random.randint(1, 6)
    pitcher_stats['Pitches'] += pitches_this_ab
    
    # Calculate strikes: 60-80% of pitches are strikes, with at least 1 strike unless walk with 1-2 pitches
    if outcome == 'WALK' and pitches_this_ab <= 2:
        strikes = 0  # Minimal pitches on walk may have no strikes
    else:
        strikes = max(1, int(pitches_this_ab * random.uniform(0.6, 0.8)))
        strikes = min(strikes, pitches_this_ab)  # Ensure strikes don't exceed pitches
    pitcher_stats['Strikes'] += strikes

    if outcome == 'WALK':
        batter_stats['BB'] += 1
        pitcher_stats['P_BB'] += 1
        return outcome, 0, 0, 1
    elif outcome.startswith('OUT'):
        batter_stats['AB'] += 1
        if outcome == 'OUT_SO':
            batter_stats['SO'] += 1
            pitcher_stats['P_SO'] += 1
        return outcome, 0, 1, 0
    else:  # Hit
        batter_stats['AB'] += 1
        batter_stats['H'] += 1
        pitcher_stats['Pitches'] += random.randint(0, 2)
        if outcome == 'SINGLE': return outcome, 0, 0, 1
        elif outcome == 'DOUBLE':
            batter_stats['2B'] += 1
            return outcome, 0, 0, 2
        elif outcome == 'TRIPLE':
            batter_stats['3B'] += 1
            return outcome, 0, 0, 3
        elif outcome == 'HOMERUN':
            batter_stats['HR'] += 1
            pitcher_stats['P_HR'] += 1
            return outcome, 1, 0, 4

def advance_runners_and_score(outcome, base_reached_by_batter, runners_on_base, batter_stats, pitcher_stats, all_player_stats_dict):
    runs_this_play = 0
    batter_id = batter_stats['id']
    new_runners = [None, None, None]  # 1B, 2B, 3B (stores player_id)

    # Simulate runner advancement (simplified)
    # Runner on 3rd
    if runners_on_base[2] is not None:
        runs_this_play += 1
        if runners_on_base[2] in all_player_stats_dict: all_player_stats_dict[runners_on_base[2]]['R'] += 1
    # Runner on 2nd
    if runners_on_base[1] is not None:
        if base_reached_by_batter >= 2 or outcome == 'SINGLE':  # Scores on Single or better
            runs_this_play += 1
            if runners_on_base[1] in all_player_stats_dict: all_player_stats_dict[runners_on_base[1]]['R'] += 1
        elif outcome == 'WALK' and runners_on_base[0] is not None and runners_on_base[2] is None:  # forced to 3rd by walk
            new_runners[2] = runners_on_base[1]
        elif base_reached_by_batter == 1 and new_runners[2] is None:  # single moves to 3rd
            new_runners[2] = runners_on_base[1]
    # Runner on 1st
    if runners_on_base[0] is not None:
        if base_reached_by_batter >= 3:  # Scores on Triple or HR
            runs_this_play += 1
            if runners_on_base[0] in all_player_stats_dict: all_player_stats_dict[runners_on_base[0]]['R'] += 1
        elif base_reached_by_batter == 2 and new_runners[2] is None:  # Double, runner to 3rd (simplified)
            new_runners[2] = runners_on_base[0]
        elif base_reached_by_batter == 2 and new_runners[2] is not None:  # Double, runner on 1st scores if 3rd was taken
            runs_this_play += 1
            if runners_on_base[0] in all_player_stats_dict: all_player_stats_dict[runners_on_base[0]]['R'] += 1
        elif base_reached_by_batter == 1:  # Single, runner to 2nd
            if new_runners[1] is None: new_runners[1] = runners_on_base[0]
            elif new_runners[2] is None: new_runners[2] = runners_on_base[0]  # if 2b taken, Rfrom1 to 3rd
        elif outcome == 'WALK':  # Walk, runner from 1实在是 moves to 2nd
            if new_runners[1] is None: new_runners[1] = runners_on_base[0]

    # Place batter
    if outcome == 'WALK':
        if new_runners[0] is None: new_runners[0] = batter_id
        elif new_runners[1] is None: new_runners[1] = batter_id  # Forced from 1st
        elif new_runners[2] is None: new_runners[2] = batter_id  # Forced from 2nd
    elif base_reached_by_batter == 1: new_runners[0] = batter_id
    elif base_reached_by_batter == 2: new_runners[1] = batter_id
    elif base_reached_by_batter == 3: new_runners[2] = batter_id
    elif base_reached_by_batter == 4:  # Homerun, batter scores
        runs_this_play += 1  # Batter scores themself
        batter_stats['R'] += 1

    # RBI Logic
    if outcome == 'HOMERUN':
        batter_stats['RBI'] += (1 + sum(1 for r_id in runners_on_base if r_id is not None))
    elif runs_this_play > 0 and not outcome.startswith('OUT'):
        batter_stats['RBI'] += runs_this_play

    pitcher_stats['ER'] += runs_this_play
    return runs_this_play, new_runners

all_player_stats = {}  # Global dict to hold all player stat objects

def format_statline(player_stats_id, is_pitcher=False):
    global all_player_stats
    player_stats_obj = all_player_stats.get(player_stats_id)

    if not player_stats_obj:
        print(f"Statline N/A for player ID {player_stats_id}")
        return

    name_pos = f"{player_stats_obj.get('name', f'Player {player_stats_id}')} ({player_stats_obj.get('pos', 'N/A')})"

    if is_pitcher:
        ip = player_stats_obj.get('IP', 0.0)
        ip_major = int(ip)
        ip_minor = int(round((ip - ip_major) * 3))
        print(f"{name_pos:<30} IP: {ip_major}.{ip_minor}, "
              f"R: {player_stats_obj.get('ER',0)}, ER: {player_stats_obj.get('ER',0)}, "
              f"BB: {player_stats_obj.get('P_BB',0)}, SO: {player_stats_obj.get('P_SO',0)}, HR: {player_stats_obj.get('P_HR',0)}, "
              f"PC-ST: {player_stats_obj.get('Pitches',0)}-{player_stats_obj.get('Strikes',0)}")
    else:
        print(f"{name_pos:<30} AB: {player_stats_obj.get('AB',0)}, R: {player_stats_obj.get('R',0)}, H: {player_stats_obj.get('H',0)}, "
              f"2B: {player_stats_obj.get('2B',0)}, 3B: {player_stats_obj.get('3B',0)}, HR: {player_stats_obj.get('HR',0)}, "
              f"RBI: {player_stats_obj.get('RBI',0)}, BB: {player_stats_obj.get('BB',0)}, SO: {player_stats_obj.get('SO',0)}")

def run_simulation(game_pk, home_team_name, away_team_name, home_lineup_ids, away_lineup_ids, home_sp_id, away_sp_id):
    global all_player_stats
    all_player_stats = {}

    print(f"\nSimulating {away_team_name} at {home_team_name}...")

    home_score = 0
    away_score = 0
    inning = 1
    top_of_inning = True
    game_over = False

    print("Fetching player names (this might take a moment)...")
    def get_player_details(player_id, default_pos_prefix=""):
        if not player_id: return None
        try:
            player_info = statsapi.get('player', {'personId': player_id})
            if player_info and player_info.get('people'):
                name = player_info['people'][0].get('fullName', f"Player {player_id}")
                primary_pos_data = player_info['people'][0].get('primaryPosition', {})
                pos_code = primary_pos_data.get('abbreviation', default_pos_prefix)
            else:
                name = f"Player {player_id}"
                pos_code = default_pos_prefix

            if player_id == home_sp_id or player_id == away_sp_id: pos_code = "P"
            elif not pos_code and default_pos_prefix: pos_code = default_pos_prefix
            elif not pos_code: pos_code = "POS"

            stats = init_player_stats(player_id, name, pos_code)
            all_player_stats[player_id] = stats
            return stats
        except Exception as e:
            name = f"Player {player_id}"
            pos_code = "P" if player_id in [home_sp_id, away_sp_id] else default_pos_prefix if default_pos_prefix else "N/A"
            stats = init_player_stats(player_id, name, pos_code)
            all_player_stats[player_id] = stats
            return stats

    home_sp_stats_obj = get_player_details(home_sp_id, "P")
    away_sp_stats_obj = get_player_details(away_sp_id, "P")

    home_lineup_stats_objs = [get_player_details(pid, f"H{i+1}") for i, pid in enumerate(home_lineup_ids)]
    away_lineup_stats_objs = [get_player_details(pid, f"V{i+1}") for i, pid in enumerate(away_lineup_ids)]

    home_lineup_stats_objs = [p for p in home_lineup_stats_objs if p]
    away_lineup_stats_objs = [p for p in away_lineup_stats_objs if p]

    if not home_sp_stats_obj or not away_sp_stats_obj or not home_lineup_stats_objs or not away_lineup_stats_objs:
        print("Critical error: Could not initialize starting players/pitchers. Aborting simulation.")
        return

    home_batter_idx = 0
    away_batter_idx = 0

    print("\n--- Starting Simulation ---")
    time.sleep(0.5)

    while not game_over:
        print("-" * 40)
        inning_half_str = "Top" if top_of_inning else "Bottom"
        print(f"{inning_half_str} of Inning {inning}   |   {away_team_name}: {away_score} - {home_team_name}: {home_score}")

        outs = 0
        runners_on_base = [None, None, None]

        current_lineup_stats = away_lineup_stats_objs if top_of_inning else home_lineup_stats_objs
        current_pitcher_stats_obj = home_sp_stats_obj if top_of_inning else away_sp_stats_obj

        if not current_lineup_stats:
            print(f"Error: No lineup for {'Away' if top_of_inning else 'Home'}. Ending inning.")
            outs = 3

        while outs < 3:
            current_batter_idx = away_batter_idx if top_of_inning else home_batter_idx
            if current_batter_idx >= len(current_lineup_stats):
                outs = 3
                break

            batter_stats_obj = current_lineup_stats[current_batter_idx]

            print(f"\nNow Batting: {batter_stats_obj['name']} ({batter_stats_obj['pos']}) for {'Away' if top_of_inning else 'Home'}")
            time.sleep(0.05)

            outcome, runs_on_play_direct_hr, outs_on_play, base_reached = simulate_at_bat(batter_stats_obj, current_pitcher_stats_obj)
            print(f"Outcome: {outcome}")

            if outs_on_play > 0:
                outs += outs_on_play
                current_pitcher_stats_obj['IP'] += (outs_on_play / 3.0)
                if outs >= 3:
                    print(f"Three outs. Inning over.")
                    break
            else:
                runs_scored_this_ab, new_runners = advance_runners_and_score(
                    outcome, base_reached, runners_on_base, batter_stats_obj, current_pitcher_stats_obj, all_player_stats
                )
                runners_on_base = new_runners

                if outcome == 'HOMERUN':
                    hr_rbi = sum(1 for r_id in runners_on_base if r_id is not None and r_id != batter_stats_obj['id']) + 1
                    print(f"HOMERUN! {batter_stats_obj['name']} scores {hr_rbi - 1} runner(s) and themself!")
                elif runs_scored_this_ab > 0:
                    print(f"{batter_stats_obj['name']} drives in {runs_scored_this_ab} run(s)!")

                if top_of_inning: away_score += runs_scored_this_ab
                else: home_score += runs_scored_this_ab

            if outs_on_play == 0 and outs < 3:
                runner_names = [all_player_stats.get(r_id, {}).get('name', 'Empty') if r_id else '-' for r_id in runners_on_base]
                print(f"Runners on: 1B:{runner_names[0]}, 2B:{runner_names[1]}, 3B:{runner_names[2]}")

            if top_of_inning:
                away_batter_idx = (away_batter_idx + 1) % len(away_lineup_stats_objs)
            else:
                home_batter_idx = (home_batter_idx + 1) % len(home_lineup_stats_objs)

            print(f"Score: {away_team_name}: {away_score} - {home_team_name}: {home_score}, Outs: {outs}")
            time.sleep(0.1)

        # End of half-inning logic
        if top_of_inning:
            top_of_inning = False
            if inning >= 9 and home_score > away_score:
                game_over = True
        else:
            top_of_inning = True
            if inning >= 9 and home_score != away_score:
                game_over = True
            elif inning >= 9 and home_score == away_score:
                inning += 1
            elif inning < 9:
                inning += 1

        if inning > 15:
            print("Game reached 15 innings, calling it.")
            game_over = True

    print("\n" + "="*20 + " FINAL " + "="*20)
    print(f"{away_team_name}: {away_score}")
    print(f"{home_team_name}: {home_score}")
    winner = "Tie"
    if away_score > home_score: winner = away_team_name
    elif home_score > away_score: winner = home_team_name
    print(f"Winner: {winner}")

    print("\n" + "--- Predicted Statlines ---")
    print(f"\n{away_team_name.upper()} Batters:")
    for player_id in away_lineup_ids: format_statline(player_id)
    print(f"\n{away_team_name.upper()} Pitcher:")
    if away_sp_id: format_statline(away_sp_id, is_pitcher=True)

    print(f"\n{home_team_name.upper()} Batters:")
    for player_id in home_lineup_ids: format_statline(player_id)
    print(f"\n{home_team_name.upper()} Pitcher:")
    if home_sp_id: format_statline(home_sp_id, is_pitcher=True)

def get_generic_lineup(team_abbr, is_home):
    """Generate a generic lineup with placeholder player IDs and names."""
    lineup = []
    prefix = "H" if is_home else "V"
    for i in range(9):
        player_id = f"generic_{team_abbr}_{prefix}{i+1}"
        player_name = f"{team_abbr} Player {i+1}"
        position = f"{prefix}{i+1}"
        lineup.append((player_id, player_name, position))
    return lineup

def get_game_details(game):
    """Extract game details and handle missing data."""
    game_pk = game.get('game_pk', None)
    away_team = game.get('away_name', 'Unknown Away Team')
    home_team = game.get('home_name', 'Unknown Home Team')
    away_id = game.get('away_id', None)
    home_id = game.get('home_id', None)
    status = game.get('status', 'Scheduled')
    game_date = game.get('game_date', datetime.now().strftime('%Y-%m-%d'))

    # Fetch lineups and starting pitchers if game_pk is available and game is not in future
    away_lineup_ids = []
    home_lineup_ids = []
    away_sp_id = None
    home_sp_id = None

    if game_pk and status in ['Scheduled', 'In Progress', 'Final']:
        try:
            game_info = statsapi.boxscore_data(game_pk)
            away_lineup_ids = game_info.get('away', {}).get('battingOrder', [])
            home_lineup_ids = game_info.get('home', {}).get('battingOrder', [])
            away_sp_id = game_info.get('away', {}).get('pitchers', [None])[0]
            home_sp_id = game_info.get('home', {}).get('pitchers', [None])[0]
        except Exception as e:
            print(f"Warning: Could not fetch boxscore data for game_pk {game_pk}: {e}")

    # Fallback to generic lineups if data is missing
    if not away_lineup_ids:
        away_lineup_ids = [pid for pid, _, _ in get_generic_lineup(away_team[:3].upper(), is_home=False)]
    if not home_lineup_ids:
        home_lineup_ids = [pid for pid, _, _ in get_generic_lineup(home_team[:3].upper(), is_home=True)]
    if not away_sp_id:
        away_sp_id = f"generic_{away_team[:3].upper()}_P"
    if not home_sp_id:
        home_sp_id = f"generic_{home_team[:3].upper()}_P"

    return {
        'game_pk': game_pk,
        'away_team': away_team,
        'home_team': home_team,
        'away_id': away_id,
        'home_id': home_id,
        'away_lineup_ids': away_lineup_ids,
        'home_lineup_ids': home_lineup_ids,
        'away_sp_id': away_sp_id,
        'home_sp_id': home_sp_id,
        'status': status,
        'game_date': game_date
    }

def main():
    today_str = date.today().strftime("%Y-%m-%d")
    print(f"Fetching games for today: {today_str}")
    try:
        games_today = statsapi.schedule(date=today_str)
    except Exception as e:
        print(f"Error fetching schedule: {e}")
        print("This could be due to no games scheduled, or an API/network issue.")
        return

    if not games_today:
        print("No games scheduled for today or unable to fetch games.")
        return

    print("\nToday's Games:")
    for i, game in enumerate(games_today):
        game_dt_str = game.get('game_datetime', '')
        display_time_str = 'Time N/A'
        game_date_str = game.get('game_date', 'Date N/A')

        if game_dt_str:
            try:
                game_dt_utc = datetime.strptime(game_dt_str, '%Y-%m-%dT%H:%M:%SZ')
                game_dt_utc = game_dt_utc.replace(tzinfo=timezone.utc)
                game_dt_local = game_dt_utc.astimezone(tz=None)
                display_time_str = game_dt_local.strftime('%I:%M %p %Z')
            except ValueError:
                display_time_str = game_dt_str.split('T')[-1].replace('Z', ' UTC') if 'T' in game_dt_str else game_dt_str

        away_name = game.get('away_name', 'Away Team N/A')
        home_name = game.get('home_name', 'Home Team N/A')
        status = game.get('status', 'Status N/A')
        print(f"{i+1}. {away_name} at {home_name} ({game_date_str} {display_time_str}) - Status: {status}")

    while True:
        try:
            choice_input = input("Select a game to simulate (number, or 'q' to quit): ")
            if choice_input.lower() == 'q':
                print("Exiting simulator.")
                return
            choice = int(choice_input) - 1
            if 0 <= choice < len(games_today):
                selected_game = games_today[choice]
                break
            else:
                print("Invalid choice. Please enter a number from the list.")
        except ValueError:
            print("Invalid input. Please enter a number.")

    # Extract game details
    game_details = get_game_details(selected_game)
    game_pk = game_details['game_pk']
    away_team = game_details['away_team']
    home_team = game_details['home_team']
    away_lineup_ids = game_details['away_lineup_ids']
    home_lineup_ids = game_details['home_lineup_ids']
    away_sp_id = game_details['away_sp_id']
    home_sp_id = game_details['home_sp_id']
    status = game_details['status']

    print(f"\nSelected Game: {away_team} at {home_team} - Status: {status}")
    if status == 'In Progress':
        print("Note: Game is in progress. Simulation will predict outcome based on generic or available data.")
    elif status == 'Final':
        print("Note: Game has ended. Simulation will predict a hypothetical outcome.")
    elif not game_pk:
        print("Warning: Game ID missing. Using generic simulation data.")

    # Run the simulation
    run_simulation(
        game_pk=game_pk,
        home_team_name=home_team,
        away_team_name=away_team,
        home_lineup_ids=home_lineup_ids,
        away_lineup_ids=away_lineup_ids,
        home_sp_id=home_sp_id,
        away_sp_id=away_sp_id
    )

if __name__ == "__main__":
    main()








#############№##########№№##№####################








#!/usr/bin/env python3
# pretty_print_breakouts.py
# Reads the enriched breakout performance data and prints it to the terminal
# with flair, including player names, statlines, context, and sorted by date/score.

import sqlite3
import pandas as pd
import numpy as np
import subprocess
import shutil
import os
import logging
import requests # For API fallback
from functools import lru_cache # For caching API calls
from datetime import datetime # For formatting date output

# --- Configuration ---
DB_PATH = "breakouts.db"
TABLE_NAME = "breakout_performances_topN_enriched" # <<-- Read from the enriched table
MAIN_DB_PATH = "mlb_data2.db" # Path to main database for player names
PEOPLE_TABLE_NAME = "people" # Assumed name for player lookup table

FIGLET_FONT = "miniwi" # User preferred font
TITLE_TEXT = "Daily Breakout Report"
SECTION_SEPARATOR = "=" * 44 # Separator length
MAX_ROWS_DISPLAY = 50 # Limit the total number of rows printed to the terminal

# --- Logging Setup ---
# Remove existing handlers to avoid duplicate logs if script is re-run
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

# --- Helper Functions ---

def is_tool(name):
    """Check whether `name` is on PATH and marked as executable."""
    return shutil.which(name) is not None

def run_command(command_list, input_text=None):
    """Runs a shell command and returns its output."""
    try:
        process = subprocess.run(
            command_list,
            input=input_text,
            text=True,
            capture_output=True,
            check=True # Raise exception on non-zero exit code
        )
        return process.stdout
    except FileNotFoundError:
        return None
    except subprocess.CalledProcessError as e:
        # Log specific error but don't stop execution
        logging.warning(f"Command '{' '.join(command_list)}' failed: {e}")
        logging.debug(f"Stderr: {e.stderr}")
        return None
    except Exception as e:
        logging.error(f"An unexpected error occurred running command '{' '.join(command_list)}': {e}")
        return None

@lru_cache(maxsize=None) # Cache API calls to avoid redundant lookups
def get_player_name_api(player_id):
    """Fetches player name and primary position from MLB Stats API as a fallback."""
    try:
        player_id_int = int(player_id)
    except (ValueError, TypeError):
        logging.warning(f"Invalid player_id format for API call: {player_id}")
        return f"ID:{player_id}", "UNK"

    url = f"https://statsapi.mlb.com/api/v1/people/{player_id_int}?hydrate=primaryPosition" # Hydrate position
    try:
        res = requests.get(url, timeout=10) # Increased timeout slightly
        res.raise_for_status()
        data = res.json()
        if data.get('people') and len(data['people']) > 0:
            person = data['people'][0]
            primary_pos = person.get('primaryPosition', {}).get('abbreviation', 'UNK')
            full_name = person.get('fullName', f"ID:{player_id}")
            return full_name, primary_pos
        else:
            logging.warning(f"No 'people' data found in API response for ID {player_id}")
            return f"ID:{player_id}", "UNK"
    except requests.exceptions.RequestException as e:
        # Log API errors less verbosely unless debugging
        logging.debug(f"API request failed for player ID {player_id}: {e}")
        return f"ID:{player_id}", "UNK"
    except Exception as e:
        logging.warning(f"Error parsing API response for player ID {player_id}: {e}")
        return f"ID:{player_id}", "UNK"


def load_player_name_map(db_path, table_name):
    """Attempts to load player ID to name and position map from a local database table."""
    logging.info(f"Attempting to load player names/pos from {db_path}, table {table_name}...")
    if not os.path.exists(db_path):
        logging.warning(f"Main database file not found: {db_path}. Will use API fallback.")
        return None, None

    name_map = {}
    pos_map = {}
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';")
            if not cursor.fetchone():
                logging.warning(f"Table '{table_name}' not found in {db_path}. Will use API fallback.")
                return None, None

            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = [info[1].lower() for info in cursor.fetchall()]
            id_col_options = ['playerid', 'player_id', 'id']
            first_name_col_options = ['namefirst', 'firstname', 'first_name']
            last_name_col_options = ['namelast', 'lastname', 'last_name']
            pos_col_options = ['pos', 'primaryposition', 'primary_position'] # Add more common pos names

            id_col = next((col for col in id_col_options if col in columns), None)
            first_name_col = next((col for col in first_name_col_options if col in columns), None)
            last_name_col = next((col for col in last_name_col_options if col in columns), None)
            pos_col = next((col for col in pos_col_options if col in columns), None)

            if not (id_col and first_name_col and last_name_col):
                 logging.warning(f"Expected name columns not found in table '{table_name}'. Will use API fallback.")
                 return None, None # Cannot proceed without names

            select_cols = [f'"{id_col}"', f'"{first_name_col}"', f'"{last_name_col}"']
            if pos_col:
                 select_cols.append(f'"{pos_col}"')
                 logging.info(f"Found position column: '{pos_col}'")
            else:
                 logging.warning(f"Position column not found in '{table_name}'. Will rely on API fallback for positions.")

            query = f"SELECT {', '.join(select_cols)} FROM {table_name}"
            logging.debug(f"Executing name query: {query}")
            df_names = pd.read_sql_query(query, conn)

            df_names['fullName'] = df_names[first_name_col].fillna('') + ' ' + df_names[last_name_col].fillna('')
            df_names['fullName'] = df_names['fullName'].str.strip()
            df_names[id_col] = pd.to_numeric(df_names[id_col], errors='coerce')
            df_names.dropna(subset=[id_col], inplace=True)
            try:
                df_names[id_col] = df_names[id_col].astype(int)
                name_map = pd.Series(df_names['fullName'].values, index=df_names[id_col]).to_dict()
                if pos_col:
                     pos_map = pd.Series(df_names[pos_col].fillna('UNK').values, index=df_names[id_col]).to_dict()
                     logging.info(f"Successfully loaded {len(name_map)} names and {len(pos_map)} positions from local DB.")
                else:
                     logging.info(f"Successfully loaded {len(name_map)} names from local DB (no position column found).")
                return name_map, pos_map
            except ValueError as ve:
                 logging.error(f"Could not convert player IDs in '{table_name}' to integers: {ve}. Using API fallback.")
                 return None, None
    except sqlite3.Error as e:
        logging.error(f"SQLite error loading player names: {e}")
        return None, None
    except Exception as e:
        logging.error(f"Error loading player names: {e}")
        return None, None

# --- Main Logic ---

def load_breakout_data(db_path, table_name):
    """Loads breakout data from the SQLite database."""
    logging.info(f"Loading data from {db_path}, table {table_name}...")
    if not os.path.exists(db_path):
        logging.error(f"Database file not found: {db_path}")
        return None
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';")
            if not cursor.fetchone():
                logging.error(f"Table '{table_name}' not found in the database.")
                return None
            df = pd.read_sql_query(f"SELECT * FROM {table_name}", conn)
            logging.info(f"Successfully loaded {len(df)} rows.")

            if 'player_id' not in df.columns: return None
            df['player_id'] = pd.to_numeric(df['player_id'], errors='coerce').astype('Int64')
            df.dropna(subset=['player_id'], inplace=True)
            df['player_id'] = df['player_id'].astype(int)

            if 'game_date' not in df.columns: return None
            df['game_date'] = pd.to_datetime(df['game_date'], errors='coerce')
            df.dropna(subset=['game_date'], inplace=True)

            # Convert stat columns to numeric, filling errors/NaNs with 0
            stat_cols = ['IP', 'H', 'R', 'ER', 'BB', 'SO', 'HR', 'outs_recorded',
                         'single', 'double', 'triple', 'AB', 'SB', 'CS', 'RBI', 'PA', 'daily_score']
            for col in stat_cols:
                 if col in df.columns:
                      df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                 else: df[col] = 0

            # Convert score columns to numeric, keeping NaNs for placeholders
            score_cols = ['actual_home_score', 'actual_away_score']
            for col in score_cols:
                 if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
                 else: df[col] = np.nan

            # Ensure context columns exist, fill with 'Unknown' or '?' if missing
            context_cols = {'ballpark': 'Unknown', 'opponent_team': 'Unknown', 'game_winner': '?'}
            for col, default in context_cols.items():
                 if col not in df.columns: df[col] = default
                 else: df[col].fillna(default, inplace=True)

            return df
    except sqlite3.Error as e:
        logging.error(f"SQLite error loading data: {e}")
        return None
    except Exception as e:
        logging.error(f"Error loading data: {e}")
        return None

def add_player_names_and_pos(df, name_map, pos_map):
    """Adds player names and positions using maps or API fallback."""
    if 'player_id' not in df.columns:
        logging.error("Missing 'player_id' column in DataFrame. Cannot add names/pos.")
        df['player_name'] = 'Error: Missing ID'
        df['position'] = 'UNK'
        return df

    df['player_id'] = df['player_id'].astype(int) # Ensure correct type

    # Initialize columns if they don't exist
    if 'player_name' not in df.columns: df['player_name'] = pd.NA
    if 'position' not in df.columns: df['position'] = 'UNK'

    # --- Get Names ---
    if name_map:
        logging.info("Mapping names using local lookup...")
        df['player_name'] = df['player_id'].map(name_map)
        missing_names = df['player_name'].isnull()
        if missing_names.any():
            logging.warning(f"{missing_names.sum()} player names not found locally. Using API fallback...")
            api_results = df.loc[missing_names, 'player_id'].apply(lambda x: get_player_name_api(int(x)))
            df.loc[missing_names, 'player_name'] = api_results.apply(lambda x: x[0])
            # If pos_map doesn't exist, fill position from API result for these missing names
            if not pos_map:
                 df.loc[missing_names, 'position'] = api_results.apply(lambda x: x[1])
        df['player_name'].fillna(df['player_id'].apply(lambda x: f"ID:{x}"), inplace=True)
    else:
        logging.info("No local name map. Using API fallback for all names and positions...")
        api_results = df['player_id'].apply(lambda x: get_player_name_api(int(x)))
        df['player_name'] = api_results.apply(lambda x: x[0])
        df['position'] = api_results.apply(lambda x: x[1])

    # --- Get Positions (if not already fetched from API) ---
    if pos_map:
         logging.info("Mapping positions using local lookup...")
         # Only map positions if the column wasn't already filled by API fallback
         needs_pos_map = df['position'].isnull() | (df['position'] == 'UNK')
         df.loc[needs_pos_map, 'position'] = df.loc[needs_pos_map, 'player_id'].map(pos_map)
         df['position'].fillna('UNK', inplace=True) # Fill any remaining UNK/NaN

    return df


def format_statline(row):
    """ Creates the formatted statline string based on player type. """
    is_pitcher = row.get('IP', 0) > 0
    position = row.get('position', 'UNK')

    if is_pitcher:
        ip_full = int(row.get('IP', 0))
        ip_partial = int(round((row.get('IP', 0) - ip_full) * 3))
        ip_str = f"{ip_full}.{ip_partial}" if ip_partial > 0 else f"{ip_full}.0"
        stats = [
            f"Position: {position}",
            f"IP: {ip_str}",
            f"H: {int(row.get('H', 0))}", # Placeholder value
            f"R: {int(row.get('R', 0))}", # Placeholder value
            f"ER: {int(row.get('ER', 0))}", # Placeholder value
            f"BB: {int(row.get('BB', 0))}",
            f"SO: {int(row.get('SO', 0))}"
        ]
    else: # Hitter
        h_calc = int(row.get('single', 0) + row.get('double', 0) + row.get('triple', 0) + row.get('HR', 0))
        h_val = int(row.get('H', h_calc))
        stats = [
            f"Position: {position}",
            f"AB: {int(row.get('AB', 0))}", # Placeholder value
            f"R: {int(row.get('R', 0))}", # Placeholder value
            f"H: {h_val}",
            f"2B: {int(row.get('double', 0))}",
            f"3B: {int(row.get('triple', 0))}",
            f"HR: {int(row.get('HR', 0))}",
            f"RBI: {int(row.get('RBI', 0))}", # Placeholder value
            f"BB: {int(row.get('BB', 0))}",
            f"SO: {int(row.get('SO', 0))}",
            f"SB: {int(row.get('SB', 0))}" # Placeholder value
        ]
    return "\n".join(stats)

def format_team_result(row):
    """ Formats the team result string using actual scores if available. """
    home_score = row.get('actual_home_score')
    away_score = row.get('actual_away_score')
    winner = row.get('game_winner', '?')

    # Try to determine winner if scores are present but winner isn't
    if winner == '?' and pd.notna(home_score) and pd.notna(away_score):
        if home_score > away_score: winner = 'H' # Assuming 'H' for home win
        elif away_score > home_score: winner = 'A' # Assuming 'A' for away win
        else: winner = 'T' # Tie

    home_score_str = str(int(home_score)) if pd.notna(home_score) else '?'
    away_score_str = str(int(away_score)) if pd.notna(away_score) else '?'
    outcome = '(W/L/?)' # Placeholder until player's team is known

    home_team = row.get('home_team', 'Home')
    away_team = row.get('away_team', 'Away')

    # Basic display of scores
    return f"TEAM RESULT: {outcome} {away_team} {away_score_str} - {home_team} {home_score_str}"


def display_data(df):
    """Formats and prints the data to the terminal in the desired format."""
    if df is None or df.empty:
        logging.warning("No breakout data to display.")
        return

    has_figlet = is_tool("figlet")
    has_lolcat = is_tool("lolcat")

    # --- Print Title ---
    title_output = TITLE_TEXT
    if has_figlet:
        figlet_command = ["figlet", "-f", FIGLET_FONT, TITLE_TEXT]
        generated_title = run_command(figlet_command)
        if generated_title: title_output = generated_title
        else: logging.warning(f"figlet font '{FIGLET_FONT}' not found or figlet failed.")

    if has_lolcat:
        lolcat_title = run_command(["lolcat"], input_text=title_output)
        print(lolcat_title if lolcat_title else title_output)
    else:
        print(title_output)

    # --- Prepare Data ---
    display_df = df.copy()

    # Sort by date (ascending), then score (descending)
    if 'game_date' in display_df.columns and 'daily_score' in display_df.columns:
        logging.info("Sorting data by game_date (ascending) and daily_score (descending)...")
        display_df['game_date'] = pd.to_datetime(display_df['game_date'])
        display_df = display_df.sort_values(by=['game_date', 'daily_score'], ascending=[True, False])
    else:
         logging.warning("Could not sort data properly due to missing 'game_date' or 'daily_score'.")

    # Limit rows AFTER sorting
    display_df = display_df.head(MAX_ROWS_DISPLAY)

    # --- Print Breakouts ---
    current_date_str = None
    for index, row in display_df.iterrows():
        row_date = row['game_date']
        day = row_date.day
        if 11 <= day <= 13: suffix = 'th'
        else: suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')
        row_date_str = row_date.strftime(f'%B {day}{suffix}, %Y')

        # Print Date Header if it's a new date
        if row_date_str != current_date_str:
            print("\n" + SECTION_SEPARATOR)
            date_header = f"{row_date_str}"
            if has_lolcat:
                 lolcat_header = run_command(["lolcat", "-a", "-d", "1", "-p", "0.8"], input_text=date_header)
                 print(lolcat_header if lolcat_header else date_header)
            else:
                 print(date_header)
            print(SECTION_SEPARATOR)
            current_date_str = row_date_str

        # Format Statline and Team Result
        statline = format_statline(row)
        team_result = format_team_result(row)
        ballpark = row.get('ballpark', 'Unknown Ballpark')
        opponent = row.get('opponent_team', 'Unknown Opponent') # Still placeholder

        # Format Player Info
        player_info = [
            f"\nPlayer: {row['player_name']} ({row['player_id']})",
            #f"Predicted Score: {row['daily_score']:.2f}", # Optionally hide score
            statline,
            f"Opponent: {opponent}", # Display opponent
            f"Ballpark: {ballpark}", # Display ballpark
            team_result # Display team result
        ]
        player_output = "\n".join(player_info)

        # Print Player Block (optionally with lolcat)
        if has_lolcat:
            lolcat_player = run_command(["lolcat", "-p", "0.5", "-S", "10"], input_text=player_output)
            print(lolcat_player if lolcat_player else player_output)
        else:
            print(player_output)

        print("-----") # Separator between players


if __name__ == "__main__":
    # 1. Load breakout data
    breakout_data = load_breakout_data(DB_PATH, TABLE_NAME)

    if breakout_data is not None and not breakout_data.empty:
        # 2. Attempt to load local player name and position map
        player_names, player_positions = load_player_name_map(MAIN_DB_PATH, PEOPLE_TABLE_NAME)

        # 3. Add names and positions to the breakout data
        breakout_data_with_context = add_player_names_and_pos(breakout_data, player_names, player_positions)

        # 4. Display the data
        display_data(breakout_data_with_context)
    else:
        logging.info("No breakout data found to display.")







#############################################






#!/usr/bin/env python3
# pretty_print_breakouts.py
# Reads the enriched breakout performance data and prints it to the terminal
# with flair, including player names, statlines, context, and sorted by date/score.

import sqlite3
import pandas as pd
import numpy as np
import subprocess
import shutil
import os
import logging
import requests # For API fallback
from functools import lru_cache # For caching API calls
from datetime import datetime # For formatting date output

# --- Configuration ---
DB_PATH = "breakouts.db"
TABLE_NAME = "breakout_performances_topN_enriched" # <<-- Read from the enriched table
MAIN_DB_PATH = "mlb_data2.db" # Path to main database for player names
PEOPLE_TABLE_NAME = "people" # Assumed name for player lookup table

FIGLET_FONT = "miniwi" # User preferred font
TITLE_TEXT = "Daily Breakout Report"
SECTION_SEPARATOR = "=" * 44 # Separator length
MAX_ROWS_DISPLAY = 50 # Limit the total number of rows printed to the terminal

# --- Logging Setup ---
# Remove existing handlers to avoid duplicate logs if script is re-run
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

# --- Helper Functions ---

def is_tool(name):
    """Check whether `name` is on PATH and marked as executable."""
    return shutil.which(name) is not None

def run_command(command_list, input_text=None):
    """Runs a shell command and returns its output."""
    try:
        process = subprocess.run(
            command_list,
            input=input_text,
            text=True,
            capture_output=True,
            check=True # Raise exception on non-zero exit code
        )
        return process.stdout
    except FileNotFoundError:
        return None
    except subprocess.CalledProcessError as e:
        logging.error(f"Error running command '{' '.join(command_list)}': {e}")
        logging.error(f"Stderr: {e.stderr}")
        return None
    except Exception as e:
        logging.error(f"An unexpected error occurred running command '{' '.join(command_list)}': {e}")
        return None

@lru_cache(maxsize=None) # Cache API calls to avoid redundant lookups
def get_player_name_api(player_id):
    """Fetches player name from MLB Stats API as a fallback."""
    try:
        player_id_int = int(player_id)
    except (ValueError, TypeError):
        logging.warning(f"Invalid player_id format for API call: {player_id}")
        return f"ID:{player_id}"

    url = f"https://statsapi.mlb.com/api/v1/people/{player_id_int}"
    try:
        res = requests.get(url, timeout=5)
        res.raise_for_status()
        data = res.json()
        if data.get('people') and len(data['people']) > 0:
            # Attempt to get primary position as well
            primary_pos = data['people'][0].get('primaryPosition', {}).get('abbreviation', 'UNK')
            full_name = data['people'][0].get('fullName', f"ID:{player_id}")
            return full_name, primary_pos # Return name and position
        else:
            logging.warning(f"No 'people' data found in API response for ID {player_id}")
            return f"ID:{player_id}", "UNK"
    except requests.exceptions.RequestException as e:
        logging.warning(f"API request failed for player ID {player_id}: {e}")
        return f"ID:{player_id}", "UNK"
    except Exception as e:
        logging.warning(f"Error parsing API response for player ID {player_id}: {e}")
        return f"ID:{player_id}", "UNK"


def load_player_name_map(db_path, table_name):
    """Attempts to load player ID to name map from a local database table."""
    logging.info(f"Attempting to load player names from {db_path}, table {table_name}...")
    if not os.path.exists(db_path):
        logging.warning(f"Main database file not found: {db_path}. Will use API fallback for names.")
        return None, None # Return None for map and positions

    name_map = {}
    pos_map = {} # Add position map
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';")
            if not cursor.fetchone():
                logging.warning(f"Table '{table_name}' not found in {db_path}. Will use API fallback for names.")
                return None, None

            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = [info[1].lower() for info in cursor.fetchall()]
            id_col_options = ['playerid', 'player_id', 'id']
            first_name_col_options = ['namefirst', 'firstname', 'first_name']
            last_name_col_options = ['namelast', 'lastname', 'last_name']
            # Add options for position column if available in people table
            pos_col_options = ['pos', 'primaryposition', 'primary_position']

            id_col = next((col for col in id_col_options if col in columns), None)
            first_name_col = next((col for col in first_name_col_options if col in columns), None)
            last_name_col = next((col for col in last_name_col_options if col in columns), None)
            pos_col = next((col for col in pos_col_options if col in columns), None) # Find position column

            if not (id_col and first_name_col and last_name_col):
                 logging.warning(f"Expected columns (ID, First Name, Last Name) not found in table '{table_name}'. Will use API fallback.")
                 return None, None

            # Fetch data including position if available
            select_cols = [f'"{id_col}"', f'"{first_name_col}"', f'"{last_name_col}"']
            if pos_col:
                 select_cols.append(f'"{pos_col}"')
            query = f"SELECT {', '.join(select_cols)} FROM {table_name}"

            logging.debug(f"Executing name query: {query}")
            df_names = pd.read_sql_query(query, conn)

            df_names['fullName'] = df_names[first_name_col].fillna('') + ' ' + df_names[last_name_col].fillna('')
            df_names['fullName'] = df_names['fullName'].str.strip()
            df_names[id_col] = pd.to_numeric(df_names[id_col], errors='coerce')
            df_names.dropna(subset=[id_col], inplace=True)
            try:
                df_names[id_col] = df_names[id_col].astype(int)
                name_map = pd.Series(df_names['fullName'].values, index=df_names[id_col]).to_dict()
                # Create position map if column was found
                if pos_col:
                     pos_map = pd.Series(df_names[pos_col].fillna('UNK').values, index=df_names[id_col]).to_dict()
                     logging.info(f"Successfully loaded {len(name_map)} player names and {len(pos_map)} positions from local DB.")
                else:
                     logging.info(f"Successfully loaded {len(name_map)} player names from local DB (position not found).")
                return name_map, pos_map
            except ValueError as ve:
                 logging.error(f"Could not convert player IDs in '{table_name}' to integers: {ve}. Using API fallback.")
                 return None, None
    except sqlite3.Error as e:
        logging.error(f"SQLite error loading player names: {e}")
        return None, None
    except Exception as e:
        logging.error(f"Error loading player names: {e}")
        return None, None

# --- Main Logic ---

def load_breakout_data(db_path, table_name):
    """Loads breakout data from the SQLite database."""
    logging.info(f"Loading data from {db_path}, table {table_name}...")
    if not os.path.exists(db_path):
        logging.error(f"Database file not found: {db_path}")
        return None
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';")
            if not cursor.fetchone():
                logging.error(f"Table '{table_name}' not found in the database.")
                return None
            df = pd.read_sql_query(f"SELECT * FROM {table_name}", conn)
            logging.info(f"Successfully loaded {len(df)} rows.")

            if 'player_id' not in df.columns: return None
            df['player_id'] = pd.to_numeric(df['player_id'], errors='coerce').astype('Int64')
            df.dropna(subset=['player_id'], inplace=True)
            df['player_id'] = df['player_id'].astype(int)

            if 'game_date' not in df.columns: return None
            df['game_date'] = pd.to_datetime(df['game_date'], errors='coerce')
            df.dropna(subset=['game_date'], inplace=True)

            # Convert stat columns to numeric, filling errors/NaNs with 0
            stat_cols = ['IP', 'H', 'R', 'ER', 'BB', 'SO', 'HR', 'outs_recorded',
                         'single', 'double', 'triple', 'AB', 'SB', 'CS', 'RBI', 'PA', 'daily_score']
            for col in stat_cols:
                 if col in df.columns:
                      df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                 else:
                      logging.warning(f"Stat column '{col}' not found in loaded data. Will default to 0.")
                      df[col] = 0

            # Convert score columns to numeric, keeping NaNs for placeholders
            score_cols = ['actual_home_score', 'actual_away_score']
            for col in score_cols:
                 if col in df.columns:
                      df[col] = pd.to_numeric(df[col], errors='coerce') # Keep NaNs
                 else:
                      df[col] = np.nan

            return df
    except sqlite3.Error as e:
        logging.error(f"SQLite error loading data: {e}")
        return None
    except Exception as e:
        logging.error(f"Error loading data: {e}")
        return None

def add_player_names_and_pos(df, name_map, pos_map):
    """Adds player names and positions using maps or API fallback."""
    if 'player_id' not in df.columns:
        logging.error("Missing 'player_id' column in DataFrame. Cannot add names/pos.")
        df['player_name'] = 'Error: Missing ID'
        df['position'] = 'UNK'
        return df

    df['player_id'] = df['player_id'].astype(int) # Ensure correct type

    # --- Get Names ---
    if name_map:
        logging.info("Mapping names using local lookup...")
        df['player_name'] = df['player_id'].map(name_map)
        missing_names = df['player_name'].isnull()
        if missing_names.any():
            logging.warning(f"{missing_names.sum()} player names not found locally. Using API fallback...")
            # Apply API only for missing names
            api_results = df.loc[missing_names, 'player_id'].apply(lambda x: get_player_name_api(int(x)))
            df.loc[missing_names, 'player_name'] = api_results.apply(lambda x: x[0]) # Get name from tuple
            # If position map doesn't exist, try to get position from API result too
            if not pos_map:
                 if 'position' not in df.columns: df['position'] = 'UNK' # Initialize if needed
                 df.loc[missing_names, 'position'] = api_results.apply(lambda x: x[1]) # Get pos from tuple
        df['player_name'].fillna(df['player_id'].apply(lambda x: f"ID:{x}"), inplace=True)
    else:
        logging.info("No local name map. Using API fallback for all names and positions...")
        api_results = df['player_id'].apply(lambda x: get_player_name_api(int(x)))
        df['player_name'] = api_results.apply(lambda x: x[0])
        df['position'] = api_results.apply(lambda x: x[1])

    # --- Get Positions (if not already fetched from API) ---
    if pos_map:
         logging.info("Mapping positions using local lookup...")
         df['position'] = df['player_id'].map(pos_map).fillna('UNK')
    elif 'position' not in df.columns: # Ensure column exists if neither map nor API provided it
         df['position'] = 'UNK'

    return df


def format_statline(row):
    """ Creates the formatted statline string based on player type. """
    is_pitcher = row.get('IP', 0) > 0
    position = row.get('position', 'UNK') # Get position if available

    if is_pitcher:
        ip_full = int(row.get('IP', 0))
        ip_partial = int(round((row.get('IP', 0) - ip_full) * 3))
        ip_str = f"{ip_full}.{ip_partial}" if ip_partial > 0 else f"{ip_full}.0"
        stats = [
            f"Position: {position}",
            f"IP: {ip_str}",
            f"H: {int(row.get('H', 0))}", # Placeholder value
            f"R: {int(row.get('R', 0))}", # Placeholder value
            f"ER: {int(row.get('ER', 0))}", # Placeholder value
            f"BB: {int(row.get('BB', 0))}",
            f"SO: {int(row.get('SO', 0))}"
        ]
    else: # Hitter
        h_calc = int(row.get('single', 0) + row.get('double', 0) + row.get('triple', 0) + row.get('HR', 0))
        h_val = int(row.get('H', h_calc))
        stats = [
            f"Position: {position}",
            f"AB: {int(row.get('AB', 0))}", # Placeholder value
            f"R: {int(row.get('R', 0))}", # Placeholder value
            f"H: {h_val}",
            f"2B: {int(row.get('double', 0))}",
            f"3B: {int(row.get('triple', 0))}",
            f"HR: {int(row.get('HR', 0))}",
            f"RBI: {int(row.get('RBI', 0))}", # Placeholder value
            f"BB: {int(row.get('BB', 0))}",
            f"SO: {int(row.get('SO', 0))}",
            f"SB: {int(row.get('SB', 0))}" # Placeholder value
        ]
    return "\n".join(stats)

def format_team_result(row):
    """ Formats the team result string using actual scores if available. """
    home_score = row.get('actual_home_score')
    away_score = row.get('actual_away_score')
    winner = row.get('game_winner', '?') # Placeholder if winner isn't stored

    # Try to determine winner if scores are present but winner isn't
    if winner == '?' and pd.notna(home_score) and pd.notna(away_score):
        if home_score > away_score: winner = 'H' # Assuming 'H' for home win
        elif away_score > home_score: winner = 'A' # Assuming 'A' for away win
        else: winner = 'T' # Tie

    # Format scores, handling potential NaNs
    home_score_str = str(int(home_score)) if pd.notna(home_score) else '?'
    away_score_str = str(int(away_score)) if pd.notna(away_score) else '?'

    # Determine W/L based on winner (needs player's team context - placeholder for now)
    outcome = '(W/L/?)' # Default placeholder

    # Get team names (assuming they were merged during enrichment)
    home_team = row.get('home_team', 'Home')
    away_team = row.get('away_team', 'Away')

    return f"TEAM RESULT: {outcome} {away_team} {away_score_str} - {home_team} {home_score_str}"


def display_data(df):
    """Formats and prints the data to the terminal in the desired format."""
    if df is None or df.empty:
        logging.warning("No breakout data to display.")
        return

    has_figlet = is_tool("figlet")
    has_lolcat = is_tool("lolcat")

    # --- Print Title ---
    title_output = TITLE_TEXT
    if has_figlet:
        figlet_command = ["figlet", "-f", FIGLET_FONT, TITLE_TEXT]
        generated_title = run_command(figlet_command)
        if generated_title: title_output = generated_title
        else: logging.warning(f"figlet font '{FIGLET_FONT}' not found or figlet failed.")

    if has_lolcat:
        lolcat_title = run_command(["lolcat"], input_text=title_output)
        print(lolcat_title if lolcat_title else title_output)
    else:
        print(title_output)

    # --- Prepare Data ---
    display_df = df.copy()

    # Sort by date (ascending), then score (descending)
    if 'game_date' in display_df.columns and 'daily_score' in display_df.columns:
        logging.info("Sorting data by game_date (ascending) and daily_score (descending)...")
        display_df['game_date'] = pd.to_datetime(display_df['game_date'])
        display_df = display_df.sort_values(by=['game_date', 'daily_score'], ascending=[True, False])
    else:
         logging.warning("Could not sort data properly due to missing 'game_date' or 'daily_score'.")

    # Limit rows AFTER sorting
    display_df = display_df.head(MAX_ROWS_DISPLAY)

    # --- Print Breakouts ---
    current_date_str = None
    for index, row in display_df.iterrows():
        row_date = row['game_date']
        # Format date with ordinal suffix (e.g., 1st, 2nd, 3rd, 4th)
        day = row_date.day
        if 11 <= day <= 13: suffix = 'th'
        else: suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')
        row_date_str = row_date.strftime(f'%B {day}{suffix}, %Y') # e.g., May 5th, 2025

        # Print Date Header if it's a new date
        if row_date_str != current_date_str:
            print("\n" + SECTION_SEPARATOR)
            date_header = f"{row_date_str}"
            if has_lolcat:
                 lolcat_header = run_command(["lolcat", "-a", "-d", "1", "-p", "0.8"], input_text=date_header)
                 print(lolcat_header if lolcat_header else date_header)
            else:
                 print(date_header)
            print(SECTION_SEPARATOR)
            current_date_str = row_date_str

        # Format Statline and Team Result
        statline = format_statline(row)
        team_result = format_team_result(row) # Format the team result string

        # Format Player Info
        player_info = [
            f"\nPlayer: {row['player_name']} ({row['player_id']})",
            f"Predicted Score: {row['daily_score']:.2f}", # Display score
            statline,
            team_result # Use the formatted team result
        ]
        player_output = "\n".join(player_info)

        # Print Player Block (optionally with lolcat)
        if has_lolcat:
            lolcat_player = run_command(["lolcat", "-p", "0.5", "-S", "10"], input_text=player_output)
            print(lolcat_player if lolcat_player else player_output)
        else:
            print(player_output)

        print("-----") # Separator between players


if __name__ == "__main__":
    # 1. Load breakout data
    breakout_data = load_breakout_data(DB_PATH, TABLE_NAME)

    if breakout_data is not None and not breakout_data.empty:
        # 2. Attempt to load local player name and position map
        player_names, player_positions = load_player_name_map(MAIN_DB_PATH, PEOPLE_TABLE_NAME)

        # 3. Add names and positions to the breakout data
        breakout_data_with_context = add_player_names_and_pos(breakout_data, player_names, player_positions)

        # 4. Display the data
        display_data(breakout_data_with_context)
    else:
        logging.info("No breakout data found to display.")













##########################№######################













###  Analysis of database files (pre-merge)



Analyzing PitchingPost_2010_2023.csv...
Columns: playerID, yearID, round, teamID, lgID, W, L, G, GS, CG, SHO, SV, IPouts, H, ER, HR, BB, SO, BAOpp, ERA, IBB, WP, HBP, BK, BFP, GF, R, SH, SF, GIDPData Types:
playerID     object
yearID        int64
round        object
teamID       object
lgID         object
W             int64
L             int64
G             int64
GS            int64
CG            int64
SHO           int64
SV            int64
IPouts        int64
H             int64
ER            int64
HR            int64
BB            int64
SO            int64
BAOpp       float64
ERA         float64
IBB         float64
WP          float64
HBP         float64
BK          float64
BFP         float64
GF            int64
R             int64
SH          float64
SF          float64
GIDP        float64
dtype: objectMissing Values:
playerID    0
yearID      0
round       0
teamID      0
lgID        0
W           0
L           0
G           0
GS          0
CG          0
SHO         0
SV          0
IPouts      0
H           0
ER          0
HR          0
BB          0
SO          0
BAOpp       0
ERA         0
IBB         0
WP          0
HBP         0
BK          0
BFP         0
GF          0
R           0
SH          0
SF          0
GIDP        0
dtype: int64
==================================================
Analyzing AllstarFull_2010_2023.csv...
Columns: playerID, yearID, gameNum, gameID, teamID, lgID, GP, startingPosData Types:
playerID        object
yearID           int64
gameNum          int64
gameID          object
teamID          object
lgID            object
GP               int64
startingPos    float64
dtype: objectMissing Values:
playerID       0
yearID         0
gameNum        0
gameID         0
teamID         0
lgID           0
GP             0
startingPos    0
dtype: int64
==================================================
Analyzing Appearances_2010_2023.csv...
Columns: yearID, teamID, lgID, playerID, G_all, GS, G_batting, G_defense, G_p, G_c, G_1b, G_2b, G_3b, G_ss, G_lf, G_cf, G_rf, G_of, G_dh, G_ph, G_prData Types:
yearID        int64
teamID       object
lgID         object
playerID     object
G_all         int64
GS            int64
G_batting     int64
G_defense     int64
G_p           int64
G_c           int64
G_1b          int64
G_2b          int64
G_3b          int64
G_ss          int64
G_lf          int64
G_cf          int64
G_rf          int64
G_of          int64
G_dh          int64
G_ph          int64
G_pr          int64
dtype: objectMissing Values:
yearID       0
teamID       0
lgID         0
playerID     0
G_all        0
GS           0
G_batting    0
G_defense    0
G_p          0
G_c          0
G_1b         0
G_2b         0
G_3b         0
G_ss         0
G_lf         0
G_cf         0
G_rf         0
G_of         0
G_dh         0
G_ph         0
G_pr         0
dtype: int64
==================================================
Analyzing People_2010_2023.csv...
Columns: ID, playerID, birthYear, birthMonth, birthDay, birthCity, birthCountry, birthState, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, bbrefID, finalGame, retroIDData Types:
ID                int64
playerID         object
birthYear       float64
birthMonth      float64
birthDay        float64
birthCity        object
birthCountry     object
birthState       object
deathYear       float64
deathMonth      float64
deathDay        float64
deathCountry     object
deathState       object
deathCity        object
nameFirst        object
nameLast         object
nameGiven        object
weight          float64
height          float64
bats             object
throws           object
debut            object
bbrefID          object
finalGame        object
retroID          object
dtype: objectMissing Values:
ID              0
playerID        0
birthYear       0
birthMonth      0
birthDay        0
birthCity       0
birthCountry    0
birthState      0
deathYear       0
deathMonth      0
deathDay        0
deathCountry    0
deathState      0
deathCity       0
nameFirst       0
nameLast        0
nameGiven       0
weight          0
height          0
bats            0
throws          0
debut           0
bbrefID         0
finalGame       0
retroID         0
dtype: int64
==================================================
Analyzing FieldingPost_2010_2023.csv...
Columns: playerID, yearID, teamID, lgID, round, POS, G, GS, InnOuts, PO, A, E, DP, TP, PB, SB, CSData Types:
playerID     object
yearID        int64
teamID       object
lgID         object
round        object
POS          object
G             int64
GS            int64
InnOuts       int64
PO            int64
A             int64
E             int64
DP            int64
TP            int64
PB          float64
SB          float64
CS          float64
dtype: objectMissing Values:
playerID    0
yearID      0
teamID      0
lgID        0
round       0
POS         0
G           0
GS          0
InnOuts     0
PO          0
A           0
E           0
DP          0
TP          0
PB          0
SB          0
CS          0
dtype: int64
==================================================
Analyzing Pitching_2010_2023.csv...
Columns: playerID, yearID, stint, teamID, lgID, W, L, G, GS, CG, SHO, SV, IPouts, H, ER, HR, BB, SO, BAOpp, ERA, IBB, WP, HBP, BK, BFP, GF, R, SH, SF, GIDPData Types:
playerID     object
yearID        int64
stint         int64
teamID       object
lgID         object
W             int64
L             int64
G             int64
GS            int64
CG            int64
SHO           int64
SV            int64
IPouts        int64
H             int64
ER            int64
HR            int64
BB            int64
SO            int64
BAOpp       float64
ERA         float64
IBB         float64
WP            int64
HBP         float64
BK            int64
BFP         float64
GF            int64
R             int64
SH          float64
SF          float64
GIDP        float64
dtype: objectMissing Values:
playerID    0
yearID      0
stint       0
teamID      0
lgID        0
W           0
L           0
G           0
GS          0
CG          0
SHO         0
SV          0
IPouts      0
H           0
ER          0
HR          0
BB          0
SO          0
BAOpp       0
ERA         0
IBB         0
WP          0
HBP         0
BK          0
BFP         0
GF          0
R           0
SH          0
SF          0
GIDP        0
dtype: int64
==================================================
Analyzing Fielding_2010_2023.csv...
Columns: playerID, yearID, stint, teamID, lgID, POS, G, GS, InnOuts, PO, A, E, DP, PB, WP, SB, CS, ZRData Types:
playerID     object
yearID        int64
stint         int64
teamID       object
lgID         object
POS          object
G             int64
GS          float64
InnOuts     float64
PO            int64
A             int64
E           float64
DP            int64
PB          float64
WP          float64
SB          float64
CS          float64
ZR          float64
dtype: objectMissing Values:
playerID    0
yearID      0
stint       0
teamID      0
lgID        0
POS         0
G           0
GS          0
InnOuts     0
PO          0
A           0
E           0
DP          0
PB          0
WP          0
SB          0
CS          0
ZR          0
dtype: int64
==================================================
Analyzing Batting_2010_2023.csv...
Columns: playerID, yearID, stint, teamID, lgID, G, G_batting, AB, R, H, 2B, 3B, HR, RBI, SB, CS, BB, SO, IBB, HBP, SH, SF, GIDP, G_oldData Types:
playerID      object
yearID         int64
stint          int64
teamID        object
lgID          object
G              int64
G_batting    float64
AB             int64
R              int64
H              int64
2B             int64
3B             int64
HR             int64
RBI          float64
SB           float64
CS           float64
BB             int64
SO           float64
IBB          float64
HBP          float64
SH           float64
SF           float64
GIDP         float64
G_old        float64
dtype: objectMissing Values:
playerID     0
yearID       0
stint        0
teamID       0
lgID         0
G            0
G_batting    0
AB           0
R            0
H            0
2B           0
3B           0
HR           0
RBI          0
SB           0
CS           0
BB           0
SO           0
IBB          0
HBP          0
SH           0
SF           0
GIDP         0
G_old        0
dtype: int64
==================================================
Analyzing Salaries_2010_2023.csv...
Columns: yearID, teamID, lgID, playerID, salaryData Types:
yearID       int64
teamID      object
lgID        object
playerID    object
salary       int64
dtype: objectMissing Values:
yearID      0
teamID      0
lgID        0
playerID    0
salary      0
dtype: int64
==================================================
Analyzing merged_lahman_2010_2023.csv...
Columns: ID, playerID, birthYear, birthMonth, birthDay, birthCity, birthCountry, birthState, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, bbrefID, finalGame, retroID, yearID, stint, teamID, lgID, G, G_batting, AB, R, H, 2B, 3B, HR, RBI, SB, CS, BB, SO, IBB, HBP, SH, SF, GIDP, G_old, stint_pitching, teamID_pitching, lgID_pitching, W, L, G_pitching, GS, CG, SHO, SV, IPouts, H_pitching, ER, HR_pitching, BB_pitching, SO_pitching, BAOpp, ERA, IBB_pitching, WP, HBP_pitching, BK, BFP, GF, R_pitching, SH_pitching, SF_pitching, GIDP_pitching, stint_fielding, teamID_fielding, lgID_fielding, POS, G_fielding, GS_fielding, InnOuts, PO, A, E, DP, PB, WP_fielding, SB_fielding, CS_fielding, ZR, teamID_salaries, lgID_salaries, salary, teamID_appearances, lgID_appearances, G_all, GS_appearances, G_batting_appearances, G_defense, G_p, G_c, G_1b, G_2b, G_3b, G_ss, G_lf, G_cf, G_rf, G_of, G_dh, G_ph, G_prData Types:
ID              int64
playerID       object
birthYear     float64
birthMonth    float64
birthDay      float64
               ...
G_rf          float64
G_of          float64
G_dh          float64
G_ph          float64
G_pr          float64
Length: 114, dtype: objectMissing Values:
ID            0
playerID      0
birthYear     0
birthMonth    0
birthDay      0
             ..
G_rf          0
G_of          0
G_dh          0
G_ph          0
G_pr          0
Length: 114, dtype: int64
==================================================
Analyzing Teams_2010_2023.csv...
Columns: yearID, lgID, teamID, franchID, divID, Rank, G, Ghome, W, L, DivWin, WCWin, LgWin, WSWin, R, AB, H, 2B, 3B, HR, BB, SO, SB, CS, HBP, SF, RA, ER, ERA, CG, SHO, SV, IPouts, HA, HRA, BBA, SOA, E, DP, FP, name, park, attendance, BPF, PPF, teamIDBR, teamIDlahman45, teamIDretroData Types:
yearID              int64
lgID               object
teamID             object
franchID           object
divID              object
Rank                int64
G                   int64
Ghome             float64
W                   int64
L                   int64
DivWin             object
WCWin              object
LgWin              object
WSWin              object
R                   int64
AB                  int64
H                   int64
2B                  int64
3B                  int64
HR                  int64
BB                  int64
SO                float64
SB                float64
CS                float64
HBP               float64
SF                float64
RA                  int64
ER                  int64
ERA               float64
CG                  int64
SHO                 int64
SV                  int64
IPouts              int64
HA                  int64
HRA                 int64
BBA                 int64
SOA                 int64
E                   int64
DP                  int64
FP                float64
name               object
park               object
attendance        float64
BPF                 int64
PPF                 int64
teamIDBR           object
teamIDlahman45     object
teamIDretro        object
dtype: objectMissing Values:
yearID            0
lgID              0
teamID            0
franchID          0
divID             0
Rank              0
G                 0
Ghome             0
W                 0
L                 0
DivWin            0
WCWin             0
LgWin             0
WSWin             0
R                 0
AB                0
H                 0
2B                0
3B                0
HR                0
BB                0
SO                0
SB                0
CS                0
HBP               0
SF                0
RA                0
ER                0
ERA               0
CG                0
SHO               0
SV                0
IPouts            0
HA                0
HRA               0
BBA               0
SOA               0
E                 0
DP                0
FP                0
name              0
park              0
attendance        0
BPF               0
PPF               0
teamIDBR          0
teamIDlahman45    0
teamIDretro       0
dtype: int64
==================================================
Analyzing BattingPost_2010_2023.csv...
Columns: yearID, round, playerID, teamID, lgID, G, AB, R, H, 2B, 3B, HR, RBI, SB, CS, BB, SO, IBB, HBP, SH, SF, GIDPData Types:
yearID       int64
round       object
playerID    object
teamID      object
lgID        object
G            int64
AB           int64
R            int64
H            int64
2B           int64
3B           int64
HR           int64
RBI          int64
SB           int64
CS           int64
BB           int64
SO           int64
IBB          int64
HBP          int64
SH           int64
SF           int64
GIDP         int64
dtype: objectMissing Values:
yearID      0
round       0
playerID    0
teamID      0
lgID        0
G           0
AB          0
R           0
H           0
2B          0
3B          0
HR          0
RBI         0
SB          0
CS          0
BB          0
SO          0
IBB         0
HBP         0
SH          0
SF          0
GIDP        0
dtype: int64
==================================================
Analyzing AwardsPlayers_2010_2023.csv...
Columns: playerID, awardID, yearID, lgID, tie, notesData Types:
playerID    object
awardID     object
yearID       int64
lgID        object
tie         object
notes       object
dtype: objectMissing Values:
playerID    0
awardID     0
yearID      0
lgID        0
tie         0
notes       0
dtype: int64
==================================================







###################################################







import sqlite3
import pandas as pd
import time
from datetime import date, timedelta, datetime
import logging
import traceback
import sys

# Attempt to import pybaseball, provide instructions if missing
try:
    from pybaseball import statcast
except ImportError:
    print("ERROR: pybaseball library not found.")
    print("Please install it by running: pip install pybaseball")
    sys.exit(1)

# --- Configuration ---
DB_PATH = "mlb_data2.db"
TABLE_NAME = "pitch_data"
# ** Adjust these dates as needed **
# Dates are inclusive. Fetch data from March 1st up to (and including) April 17th.
FETCH_START_DATE = "2025-03-01"
FETCH_END_DATE = "2025-04-17" # Day before the last failed prediction date
# Fetch data in smaller chunks to avoid timeouts and be polite to the API
CHUNK_DAYS = 3
# Delay between fetching chunks (in seconds)
FETCH_DELAY = 5

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def get_target_columns(db_path, table_name):
    """Gets the list of column names from the specified database table."""
    logging.info(f"Getting column names from table '{table_name}' in {db_path}")
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = [info[1] for info in cursor.fetchall()]
            logging.info(f"Found {len(columns)} columns in '{table_name}'.")
            return columns
    except sqlite3.Error as e:
        logging.error(f"SQLite error getting columns for '{table_name}': {e}")
        return None
    except Exception as e:
        logging.error(f"Unexpected error getting columns: {e}")
        return None

def fetch_statcast_data_chunk(start_dt_str, end_dt_str):
    """Fetches Statcast data for a specific date range using pybaseball."""
    logging.info(f"Fetching Statcast data from {start_dt_str} to {end_dt_str}...")
    try:
        # pybaseball statcast function retrieves the data
        data = statcast(start_dt=start_dt_str, end_dt=end_dt_str)
        if data is None or data.empty:
            logging.warning(f"No data returned from pybaseball for {start_dt_str} to {end_dt_str}.")
            return pd.DataFrame() # Return empty DataFrame if no data
        logging.info(f"Successfully fetched {len(data)} rows for {start_dt_str} to {end_dt_str}.")
        return data
    except Exception as e:
        logging.error(f"Error fetching Statcast data for {start_dt_str} to {end_dt_str}: {e}")
        logging.error(traceback.format_exc()) # Log full traceback for fetch errors
        return pd.DataFrame() # Return empty DataFrame on error


def clean_and_prepare_data(df, target_columns):
    """Cleans and selects columns from fetched data to match the target table."""
    logging.info(f"Cleaning and preparing {len(df)} fetched rows...")
    if df.empty:
        return df

    # Identify columns present in both fetched data and target table
    cols_to_keep = [col for col in target_columns if col in df.columns]
    missing_cols = [col for col in target_columns if col not in df.columns]

    if missing_cols:
        logging.warning(f"Target columns missing from fetched Statcast data: {missing_cols}. These columns will be NULL in the DB.")
        # Add missing columns filled with None (or appropriate default)
        for col in missing_cols:
            df[col] = None # Or pd.NA

    df_cleaned = df[cols_to_keep].copy()

    # --- Data Type Conversions (Add more as needed based on schema) ---
    # Convert game_date to string format compatible with DB TIMESTAMP (if needed)
    if 'game_date' in df_cleaned.columns:
         # pybaseball usually returns datetime objects, format if necessary
         # Example: df_cleaned['game_date'] = pd.to_datetime(df_cleaned['game_date']).dt.strftime('%Y-%m-%d %H:%M:%S')
         # Ensure it's datetime before potential conversion
         df_cleaned['game_date'] = pd.to_datetime(df_cleaned['game_date'], errors='coerce')


    # Convert potential float IDs to integers where appropriate (handle NaNs)
    int_cols = ['batter', 'pitcher', 'zone', 'balls', 'strikes', 'game_year', 'outs_when_up',
                 'inning', 'hit_location', 'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5',
                 'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'game_pk', 'pitcher.1',
                 'fielder_2.1', 'at_bat_number', 'pitch_number', 'home_score', 'away_score',
                 'bat_score', 'fld_score', 'post_away_score', 'post_home_score',
                 'post_bat_score', 'post_fld_score', 'spin_axis', 'on_1b', 'on_2b', 'on_3b'] # Add relevant int cols from schema
    for col in int_cols:
        if col in df_cleaned.columns:
            # Convert to nullable integer type (Int64) to handle potential NaNs/None
            df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce').astype('Int64')


    # Convert potential object columns to numeric where appropriate
    numeric_cols = ['release_speed', 'release_pos_x', 'release_pos_z', 'pfx_x', 'pfx_z',
                    'plate_x', 'plate_z', 'hc_x', 'hc_y', 'sz_top', 'sz_bot', 'hit_distance_sc',
                    'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate',
                    'release_extension', 'release_pos_y', 'estimated_ba_using_speedangle',
                    'estimated_woba_using_speedangle', 'woba_value', 'bat_speed', 'swing_length',
                    'delta_home_win_exp', 'delta_run_exp'] # Add relevant numeric cols from schema
    for col in numeric_cols:
         if col in df_cleaned.columns:
              df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')

    logging.info(f"Data cleaning complete. {len(df_cleaned)} rows prepared.")
    return df_cleaned


def append_to_db(df, db_path, table_name):
    """Appends the DataFrame to the specified SQLite table."""
    if df.empty:
        logging.info("No data to append to the database.")
        return 0

    logging.info(f"Appending {len(df)} rows to table '{table_name}' in {db_path}...")
    rows_added = 0
    try:
        with sqlite3.connect(db_path) as conn:
            # Use pandas to_sql for easier appending
            df.to_sql(name=table_name, con=conn, if_exists='append', index=False)
            rows_added = len(df)
            logging.info(f"Successfully appended {rows_added} rows.")
    except sqlite3.Error as e:
        logging.error(f"SQLite error appending data to '{table_name}': {e}")
        logging.error("Data that failed to append (first 5 rows):")
        try:
            logging.error(df.head().to_string()) # Log first few rows of failing data
        except Exception as log_e:
             logging.error(f"Could not log failing data: {log_e}")
    except Exception as e:
        logging.error(f"Unexpected error appending data: {e}")
        logging.error(traceback.format_exc())

    return rows_added

# --- Main Execution Logic ---
if __name__ == "__main__":
    logging.info("--- Starting MLB Data Update Script ---")

    # 1. Get target table columns
    target_columns = get_target_columns(DB_PATH, TABLE_NAME)
    if not target_columns:
        logging.error("Could not get target columns. Aborting.")
        sys.exit(1)

    # 2. Define overall date range
    try:
        start_date = datetime.strptime(FETCH_START_DATE, '%Y-%m-%d').date()
        end_date = datetime.strptime(FETCH_END_DATE, '%Y-%m-%d').date()
        logging.info(f"Target date range: {start_date} to {end_date}")
    except ValueError:
        logging.error(f"Invalid date format in FETCH_START_DATE or FETCH_END_DATE. Use YYYY-MM-DD.")
        sys.exit(1)

    # 3. Loop through date range in chunks
    current_date = start_date
    total_rows_added = 0
    while current_date <= end_date:
        chunk_end_date = min(current_date + timedelta(days=CHUNK_DAYS - 1), end_date)
        start_dt_str = current_date.strftime('%Y-%m-%d')
        end_dt_str = chunk_end_date.strftime('%Y-%m-%d')

        # Fetch data for the chunk
        fetched_df = fetch_statcast_data_chunk(start_dt_str, end_dt_str)

        if not fetched_df.empty:
            # Clean and prepare
            cleaned_df = clean_and_prepare_data(fetched_df, target_columns)
            # Append to DB
            rows_added = append_to_db(cleaned_df, DB_PATH, TABLE_NAME)
            total_rows_added += rows_added
            # Optional: Explicitly delete dataframes to free memory
            del fetched_df
            del cleaned_df
            import gc
            gc.collect()

        # Move to the next chunk start date
        current_date = chunk_end_date + timedelta(days=1)

        # Add a delay before the next fetch
        if current_date <= end_date:
            logging.info(f"Waiting {FETCH_DELAY} seconds before next chunk...")
            time.sleep(FETCH_DELAY)

    logging.info(f"--- Data Update Script Finished ---")
    logging.info(f"Total rows added to '{TABLE_NAME}': {total_rows_added}")







##########################################






Analyzing PitchingPost_2010_2023.csv...
Columns: playerID, yearID, round, teamID, lgID, W, L, G, GS, CG, SHO, SV, IPouts, H, ER, HR, BB, SO, BAOpp, ERA, IBB, WP, HBP, BK, BFP, GF, R, SH, SF, GIDPData Types:
playerID     object
yearID        int64
round        object
teamID       object
lgID         object
W             int64
L             int64
G             int64
GS            int64
CG            int64
SHO           int64
SV            int64
IPouts        int64
H             int64
ER            int64
HR            int64
BB            int64
SO            int64
BAOpp       float64
ERA         float64
IBB         float64
WP          float64
HBP         float64
BK          float64
BFP         float64
GF            int64
R             int64
SH          float64
SF          float64
GIDP        float64
dtype: objectMissing Values:
playerID    0
yearID      0
round       0
teamID      0
lgID        0
W           0
L           0
G           0
GS          0
CG          0
SHO         0
SV          0
IPouts      0
H           0
ER          0
HR          0
BB          0
SO          0
BAOpp       0
ERA         0
IBB         0
WP          0
HBP         0
BK          0
BFP         0
GF          0
R           0
SH          0
SF          0
GIDP        0
dtype: int64
==================================================
Analyzing AllstarFull_2010_2023.csv...
Columns: playerID, yearID, gameNum, gameID, teamID, lgID, GP, startingPosData Types:
playerID        object
yearID           int64
gameNum          int64
gameID          object
teamID          object
lgID            object
GP               int64
startingPos    float64
dtype: objectMissing Values:
playerID       0
yearID         0
gameNum        0
gameID         0
teamID         0
lgID           0
GP             0
startingPos    0
dtype: int64
==================================================
Analyzing Appearances_2010_2023.csv...
Columns: yearID, teamID, lgID, playerID, G_all, GS, G_batting, G_defense, G_p, G_c, G_1b, G_2b, G_3b, G_ss, G_lf, G_cf, G_rf, G_of, G_dh, G_ph, G_prData Types:
yearID        int64
teamID       object
lgID         object
playerID     object
G_all         int64
GS            int64
G_batting     int64
G_defense     int64
G_p           int64
G_c           int64
G_1b          int64
G_2b          int64
G_3b          int64
G_ss          int64
G_lf          int64
G_cf          int64
G_rf          int64
G_of          int64
G_dh          int64
G_ph          int64
G_pr          int64
dtype: objectMissing Values:
yearID       0
teamID       0
lgID         0
playerID     0
G_all        0
GS           0
G_batting    0
G_defense    0
G_p          0
G_c          0
G_1b         0
G_2b         0
G_3b         0
G_ss         0
G_lf         0
G_cf         0
G_rf         0
G_of         0
G_dh         0
G_ph         0
G_pr         0
dtype: int64
==================================================
Analyzing People_2010_2023.csv...
Columns: ID, playerID, birthYear, birthMonth, birthDay, birthCity, birthCountry, birthState, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, bbrefID, finalGame, retroIDData Types:
ID                int64
playerID         object
birthYear       float64
birthMonth      float64
birthDay        float64
birthCity        object
birthCountry     object
birthState       object
deathYear       float64
deathMonth      float64
deathDay        float64
deathCountry     object
deathState       object
deathCity        object
nameFirst        object
nameLast         object
nameGiven        object
weight          float64
height          float64
bats             object
throws           object
debut            object
bbrefID          object
finalGame        object
retroID          object
dtype: objectMissing Values:
ID              0
playerID        0
birthYear       0
birthMonth      0
birthDay        0
birthCity       0
birthCountry    0
birthState      0
deathYear       0
deathMonth      0
deathDay        0
deathCountry    0
deathState      0
deathCity       0
nameFirst       0
nameLast        0
nameGiven       0
weight          0
height          0
bats            0
throws          0
debut           0
bbrefID         0
finalGame       0
retroID         0
dtype: int64
==================================================
Analyzing FieldingPost_2010_2023.csv...
Columns: playerID, yearID, teamID, lgID, round, POS, G, GS, InnOuts, PO, A, E, DP, TP, PB, SB, CSData Types:
playerID     object
yearID        int64
teamID       object
lgID         object
round        object
POS          object
G             int64
GS            int64
InnOuts       int64
PO            int64
A             int64
E             int64
DP            int64
TP            int64
PB          float64
SB          float64
CS          float64
dtype: objectMissing Values:
playerID    0
yearID      0
teamID      0
lgID        0
round       0
POS         0
G           0
GS          0
InnOuts     0
PO          0
A           0
E           0
DP          0
TP          0
PB          0
SB          0
CS          0
dtype: int64
==================================================
Analyzing Pitching_2010_2023.csv...
Columns: playerID, yearID, stint, teamID, lgID, W, L, G, GS, CG, SHO, SV, IPouts, H, ER, HR, BB, SO, BAOpp, ERA, IBB, WP, HBP, BK, BFP, GF, R, SH, SF, GIDPData Types:
playerID     object
yearID        int64
stint         int64
teamID       object
lgID         object
W             int64
L             int64
G             int64
GS            int64
CG            int64
SHO           int64
SV            int64
IPouts        int64
H             int64
ER            int64
HR            int64
BB            int64
SO            int64
BAOpp       float64
ERA         float64
IBB         float64
WP            int64
HBP         float64
BK            int64
BFP         float64
GF            int64
R             int64
SH          float64
SF          float64
GIDP        float64
dtype: objectMissing Values:
playerID    0
yearID      0
stint       0
teamID      0
lgID        0
W           0
L           0
G           0
GS          0
CG          0
SHO         0
SV          0
IPouts      0
H           0
ER          0
HR          0
BB          0
SO          0
BAOpp       0
ERA         0
IBB         0
WP          0
HBP         0
BK          0
BFP         0
GF          0
R           0
SH          0
SF          0
GIDP        0
dtype: int64
==================================================
Analyzing Fielding_2010_2023.csv...
Columns: playerID, yearID, stint, teamID, lgID, POS, G, GS, InnOuts, PO, A, E, DP, PB, WP, SB, CS, ZRData Types:
playerID     object
yearID        int64
stint         int64
teamID       object
lgID         object
POS          object
G             int64
GS          float64
InnOuts     float64
PO            int64
A             int64
E           float64
DP            int64
PB          float64
WP          float64
SB          float64
CS          float64
ZR          float64
dtype: objectMissing Values:
playerID    0
yearID      0
stint       0
teamID      0
lgID        0
POS         0
G           0
GS          0
InnOuts     0
PO          0
A           0
E           0
DP          0
PB          0
WP          0
SB          0
CS          0
ZR          0
dtype: int64
==================================================
Analyzing Batting_2010_2023.csv...
Columns: playerID, yearID, stint, teamID, lgID, G, G_batting, AB, R, H, 2B, 3B, HR, RBI, SB, CS, BB, SO, IBB, HBP, SH, SF, GIDP, G_oldData Types:
playerID      object
yearID         int64
stint          int64
teamID        object
lgID          object
G              int64
G_batting    float64
AB             int64
R              int64
H              int64
2B             int64
3B             int64
HR             int64
RBI          float64
SB           float64
CS           float64
BB             int64
SO           float64
IBB          float64
HBP          float64
SH           float64
SF           float64
GIDP         float64
G_old        float64
dtype: objectMissing Values:
playerID     0
yearID       0
stint        0
teamID       0
lgID         0
G            0
G_batting    0
AB           0
R            0
H            0
2B           0
3B           0
HR           0
RBI          0
SB           0
CS           0
BB           0
SO           0
IBB          0
HBP          0
SH           0
SF           0
GIDP         0
G_old        0
dtype: int64
==================================================
Analyzing Salaries_2010_2023.csv...
Columns: yearID, teamID, lgID, playerID, salaryData Types:
yearID       int64
teamID      object
lgID        object
playerID    object
salary       int64
dtype: objectMissing Values:
yearID      0
teamID      0
lgID        0
playerID    0
salary      0
dtype: int64
==================================================
Analyzing merged_lahman_2010_2023.csv...
Columns: ID, playerID, birthYear, birthMonth, birthDay, birthCity, birthCountry, birthState, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, bbrefID, finalGame, retroID, yearID, stint, teamID, lgID, G, G_batting, AB, R, H, 2B, 3B, HR, RBI, SB, CS, BB, SO, IBB, HBP, SH, SF, GIDP, G_old, stint_pitching, teamID_pitching, lgID_pitching, W, L, G_pitching, GS, CG, SHO, SV, IPouts, H_pitching, ER, HR_pitching, BB_pitching, SO_pitching, BAOpp, ERA, IBB_pitching, WP, HBP_pitching, BK, BFP, GF, R_pitching, SH_pitching, SF_pitching, GIDP_pitching, stint_fielding, teamID_fielding, lgID_fielding, POS, G_fielding, GS_fielding, InnOuts, PO, A, E, DP, PB, WP_fielding, SB_fielding, CS_fielding, ZR, teamID_salaries, lgID_salaries, salary, teamID_appearances, lgID_appearances, G_all, GS_appearances, G_batting_appearances, G_defense, G_p, G_c, G_1b, G_2b, G_3b, G_ss, G_lf, G_cf, G_rf, G_of, G_dh, G_ph, G_prData Types:
ID              int64
playerID       object
birthYear     float64
birthMonth    float64
birthDay      float64
               ...
G_rf          float64
G_of          float64
G_dh          float64
G_ph          float64
G_pr          float64
Length: 114, dtype: objectMissing Values:
ID            0
playerID      0
birthYear     0
birthMonth    0
birthDay      0
             ..
G_rf          0
G_of          0
G_dh          0
G_ph          0
G_pr          0
Length: 114, dtype: int64
==================================================
Analyzing Teams_2010_2023.csv...
Columns: yearID, lgID, teamID, franchID, divID, Rank, G, Ghome, W, L, DivWin, WCWin, LgWin, WSWin, R, AB, H, 2B, 3B, HR, BB, SO, SB, CS, HBP, SF, RA, ER, ERA, CG, SHO, SV, IPouts, HA, HRA, BBA, SOA, E, DP, FP, name, park, attendance, BPF, PPF, teamIDBR, teamIDlahman45, teamIDretroData Types:
yearID              int64
lgID               object
teamID             object
franchID           object
divID              object
Rank                int64
G                   int64
Ghome             float64
W                   int64
L                   int64
DivWin             object
WCWin              object
LgWin              object
WSWin              object
R                   int64
AB                  int64
H                   int64
2B                  int64
3B                  int64
HR                  int64
BB                  int64
SO                float64
SB                float64
CS                float64
HBP               float64
SF                float64
RA                  int64
ER                  int64
ERA               float64
CG                  int64
SHO                 int64
SV                  int64
IPouts              int64
HA                  int64
HRA                 int64
BBA                 int64
SOA                 int64
E                   int64
DP                  int64
FP                float64
name               object
park               object
attendance        float64
BPF                 int64
PPF                 int64
teamIDBR           object
teamIDlahman45     object
teamIDretro        object
dtype: objectMissing Values:
yearID            0
lgID              0
teamID            0
franchID          0
divID             0
Rank              0
G                 0
Ghome             0
W                 0
L                 0
DivWin            0
WCWin             0
LgWin             0
WSWin             0
R                 0
AB                0
H                 0
2B                0
3B                0
HR                0
BB                0
SO                0
SB                0
CS                0
HBP               0
SF                0
RA                0
ER                0
ERA               0
CG                0
SHO               0
SV                0
IPouts            0
HA                0
HRA               0
BBA               0
SOA               0
E                 0
DP                0
FP                0
name              0
park              0
attendance        0
BPF               0
PPF               0
teamIDBR          0
teamIDlahman45    0
teamIDretro       0
dtype: int64
==================================================
Analyzing BattingPost_2010_2023.csv...
Columns: yearID, round, playerID, teamID, lgID, G, AB, R, H, 2B, 3B, HR, RBI, SB, CS, BB, SO, IBB, HBP, SH, SF, GIDPData Types:
yearID       int64
round       object
playerID    object
teamID      object
lgID        object
G            int64
AB           int64
R            int64
H            int64
2B           int64
3B           int64
HR           int64
RBI          int64
SB           int64
CS           int64
BB           int64
SO           int64
IBB          int64
HBP          int64
SH           int64
SF           int64
GIDP         int64
dtype: objectMissing Values:
yearID      0
round       0
playerID    0
teamID      0
lgID        0
G           0
AB          0
R           0
H           0
2B          0
3B          0
HR          0
RBI         0
SB          0
CS          0
BB          0
SO          0
IBB         0
HBP         0
SH          0
SF          0
GIDP        0
dtype: int64
==================================================
Analyzing AwardsPlayers_2010_2023.csv...
Columns: playerID, awardID, yearID, lgID, tie, notesData Types:
playerID    object
awardID     object
yearID       int64
lgID        object
tie         object
notes       object
dtype: objectMissing Values:
playerID    0
awardID     0
yearID      0
lgID        0
tie         0
notes       0
dtype: int64
================================================== pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.feature_selection import mutual_info_regression
import matplotlib.pyplot as plt
import seaborn as sns
import sqlite3

# Load the merged dataframe
df = pd.read_csv('lahman_data_processed/merged_lahman_2010_2023.csv', low_memory=False)

# Enrich with SQLite data
def enrich_with_sqlite_data(lahman_df, db_path='mlb_data2.db', table_name='statcast'):
    try:
        conn = sqlite3.connect(db_path)
        query = f"""
        SELECT playerID, yearID,
               AVG(pitch_velocity) as avg_pitch_velocity,
               AVG(exit_velocity) as avg_exit_velocity
        FROM {table_name}
        WHERE yearID BETWEEN 2010 AND 2023
        GROUP BY playerID, yearID
        """
        sqlite_df = pd.read_sql_query(query, conn)
        conn.close()
        enriched_df = lahman_df.merge(sqlite_df, on=['playerID', 'yearID'], how='left')
        enriched_df['avg_pitch_velocity'] = enriched_df['avg_pitch_velocity'].fillna(enriched_df['avg_pitch_velocity'].median())
        enriched_df['avg_exit_velocity'] = enriched_df['avg_exit_velocity'].fillna(enriched_df['avg_exit_velocity'].median())
        print("\nEnriched dataset with SQLite features:")
        print(enriched_df[['playerID', 'yearID', 'avg_pitch_velocity', 'avg_exit_velocity']].head())
        return enriched_df
    except Exception as e:
        print(f"Error enriching with SQLite data: {e}")
        return lahman_df

# Plot correlation matrix
def plot_correlation_matrix(df, features, target=None, filename='correlation_matrix.png'):
    corr = df[features].corr()
    plt.figure(figsize=(12, 10))
    sns.heatmap(corr, annot=False, cmap='coolwarm')
    plt.title(f'Correlation Matrix (Target: {target if target else "None"})')
    plt.savefig(filename)
    plt.close()
    if target:
        target_corr = corr[target].sort_values(ascending=False)
        print(f"\nCorrelations with {target}:")
        print(target_corr)

# Compute feature importance
def compute_feature_importance(df, features, target, filename='feature_importance.png'):
    X = df[features].fillna(0)
    y = df[target].fillna(0)
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X, y)
    importances = rf.feature_importances_
    indices = np.argsort(importances)[::-1]
    print(f"\nFeature ranking for {target}:")
    for f in range(X.shape[1]):
        print(f"{f + 1}. {features[indices[f]]} ({importances[indices[f]]:.4f})")
    plt.figure(figsize=(12, 6))
    plt.title(f"Feature Importances for {target}")
    plt.bar(range(X.shape[1]), importances[indices], align="center")
    plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=90)
    plt.tight_layout()
    plt.savefig(filename)
    plt.close()

# Generate interaction features and mutual information
def generate_interaction_features(df, features, target, prefix=''):
    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
    X = df[features].fillna(0)
    poly_features = poly.fit_transform(X)
    poly_feature_names = [f"{prefix}{name}" for name in poly.get_feature_names_out(features)]
    poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=df.index)
    df_combined = pd.concat([df, poly_df], axis=1)
    mi_scores = mutual_info_regression(poly_features, df[target].fillna(0))
    mi_df = pd.DataFrame({'Feature': poly_feature_names, 'MI_Score': mi_scores})
    mi_df = mi_df.sort_values('MI_Score', ascending=False)
    print(f"\nMutual Information Scores for {target} (Top 10):")
    print(mi_df.head(10))
    return df_combined, mi_df

# Compute rolling stats and breakout detection
def compute_rolling_stats_and_breakouts(df, target, group_col='playerID', time_col='yearID', window=2, threshold=1.5):
    df_sorted = df.sort_values([group_col, time_col])
    df_sorted[f'{target}_roll_mean'] = df_sorted.groupby(group_col)[target].transform(lambda x: x.rolling(window, min_periods=1).mean())
    df_sorted[f'{target}_roll_std'] = df_sorted.groupby(group_col)[target].transform(lambda x: x.rolling(window, min_periods=1).std())
    df_sorted[f'{target}_breakout'] = (df_sorted[target] > df_sorted[f'{target}_roll_mean'] + threshold * df_sorted[f'{target}_roll_std']).astype(int)
    breakout_players = df_sorted[df_sorted[f'{target}_breakout'] == 1][group_col].unique()[:5]
    for player in breakout_players:
        player_data = df_sorted[df_sorted[group_col] == player]
        plt.figure(figsize=(10, 6))
        plt.plot(player_data[time_col], player_data[target], label=target)
        plt.plot(player_data[time_col], player_data[f'{target}_roll_mean'], label='Rolling Mean')
        plt.scatter(player_data[player_data[f'{target}_breakout'] == 1][time_col], 
                    player_data[player_data[f'{target}_breakout'] == 1][target], c='red', label='Breakout')
        plt.title(f"{target} Trend for {player}")
        plt.legend()
        plt.savefig(f'lahman_data_processed/{target}_trend_{player}.png')
        plt.close()
    print(f"\nNumber of breakout seasons for {target}: {df_sorted[f'{target}_breakout'].sum()}")
    return df_sorted

# Compute lag correlation
def compute_lag_correlation(df, target, group_col='playerID', time_col='yearID'):
    df_sorted = df.sort_values([group_col, time_col])
    df_sorted[f'{target}_lag1'] = df_sorted.groupby(group_col)[target].shift(1)
    lag_corr = df_sorted[[target, f'{target}_lag1']].corr().iloc[0, 1]
    print(f"\nCorrelation between {target} and {target}_lag1: {lag_corr:.4f}")

# Enrich data
print("Enriching Lahman data with SQLite game-level metrics...")
df_enriched = enrich_with_sqlite_data(df)
df_enriched.to_csv('lahman_data_processed/enriched_lahman_2010_2023.csv', index=False)

# Separate into batters and pitchers
batters = df_enriched[df_enriched['AB'] > 0].copy()
pitchers = df_enriched[df_enriched['IPouts'] > 0].copy()

# Analysis for batters
print("\n=== Analyzing Batters ===")
target_batters = 'HR'
features_batters = [col for col in batters.columns 
                    if batters[col].dtype in ['float64', 'int64'] and col != target_batters 
                    and col not in ['ID', 'yearID']] + ['avg_exit_velocity']
plot_correlation_matrix(batters, features_batters, target_batters, 'correlation_matrix_batters.png')
compute_feature_importance(batters, features_batters, target_batters, 'feature_importance_batters.png')
compute_lag_correlation(batters, target_batters)
print("Generating interaction features for batters...")
batters_combined, mi_batters = generate_interaction_features(batters, features_batters, target_batters, 'bat_')
batters_combined.to_csv('lahman_data_processed/batters_engineered_features.csv', index=False)
mi_batters.to_csv('lahman_data_processed/batters_mi_scores.csv', index=False)
print("Computing rolling stats and breakouts for batters...")
batters_rolling = compute_rolling_stats_and_breakouts(batters, target_batters)
batters_rolling.to_csv('lahman_data_processed/batters_rolling_breakouts.csv', index=False)

# Analysis for pitchers
print("\n=== Analyzing Pitchers ===")
target_pitchers = 'SO_pitching'
features_pitchers = [col for col in pitchers.columns 
                     if pitchers[col].dtype in ['float64', 'int64'] and col != target_pitchers 
                     and col not in ['ID', 'yearID']] + ['avg_pitch_velocity']
plot_correlation_matrix(pitchers, features_pitchers, target_pitchers, 'correlation_matrix_pitchers.png')
compute_feature_importance(pitchers, features_pitchers, target_pitchers, 'feature_importance_pitchers.png')
compute_lag_correlation(pitchers, target_pitchers)
print("Generating interaction features for pitchers...")
pitchers_combined, mi_pitchers = generate_interaction_features(pitchers, features_pitchers, target_pitchers, 'pit_')
pitchers_combined.to_csv('lahman_data_processed/pitchers_engineered_features.csv', index=False)
mi_pitchers.to_csv('lahman_data_processed/pitchers_mi_scores.csv', index=False)
print("Computing rolling stats and breakouts for pitchers...")
pitchers_rolling = compute_rolling_stats_and_breakouts(pitchers, target_pitchers)
pitchers_rolling.to_csv('lahman_data_processed/pitchers_rolling_breakouts.csv', index=False)

print("\nAnalysis complete. Check saved plots and CSVs for results.")
